---
title: "Corpus Preparation"
author: "Dana"
date: "29/03/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## PhD Corpus Extraction and Preparation

In this markdown I will summarise all the steps needed to prepare the original corpus obtained from C. Purschke (cf. Hovy & Purschke, 2018). Not all steps will run in the markdown, but all necessary code will be documented. 

The first step is handling the large json files on my machine. In order to trial a couple of lines of the corpus, bash/terminal (on Mac) was used to extract parts of the corpus. This chunk gets the first 10 lines of a file and saves it in a test.json.

```{r bash 1}
head -n 10 /Users/dana/Desktop/jodel_archive.json > test.json
```

In case the last line of the json is incomplete (which would prevent it from being read in), the next chunk will delete the last line as it takes all lines except the last and creates a new active.json file.

```{r bash 2}
head -$(($(wc -l < jodel_archive.json) - 1)) jodel_archive.json > active.json
```

In order to run the corpus on the BEAR HPC it was necessary to split the two original files up in multiple smaller files, which could then run parallel. The next chunk splits up the original file into new files with each 100000 lines. The prefix for all new files is XY.

```{r bash 3}
split -l 100000 data_ling/data_active/active.json XY
```

## Unpacking json

The json structure is nested. This means information is embedded in a tree structure, which needs to be extracted in order to make all posts in the corpus accessible. This next chunk first takes a json file as input and creates an initial data frame. Then the first level of the tree structure is extracted by using the flatten function. Only four columns then are used in a new smaller data frame as most of the detailed information is not necessary for an initial analysis. Then the new corpus was created. The next step is a for loop that extracts the child posts from their one cell and appends them to the corpus, so that for all posts message, time stamp, ID and location are available. After that the corpus is made into a data frame and column names are added. Then the corpus can be exported.

```{r unnest}
library(dplyr)
library(purrr)
library(jsonlite)
df <- stream_in(file("/rds/projects/g/grievej-german-dialect-profiling/100k/1.json"))
df <- jsonlite::flatten(df, recursive = TRUE)
df_small <- select(df, message, created_at, location.name, post_id, children)
corpus <- cbind(df_small$message, df_small$created_at, df_small$location.name, df_small$post_id)
for (i in 1:nrow(df))
{
  
  children <- as.data.frame(df_small$children[i])
  children_split <- cbind(children$message, children$created_at, children$location$name, children$post_id)
  corpus <- rbind(corpus, children_split)
}
corpus <- as.data.frame(corpus)
colnames(corpus) <- c("message", "created_at", "location", "post_id")
write.csv(corpus,"part1.csv", fileEncoding = "UTF-8", row.names = FALSE)
```

In order to see if the code was running correctly, time stamps were created to check on progress.

```{r time}
#logging 
print("Start:")
currentTime <- Sys.time()
print(currentTime)
```

This process was done for all 29 split up files of the original two json files. Then all these files were put back together to create one large corpus file for analysis. Also the original split of the two json files was kept in case smaller parts of the corpus were needed.
For that all small files were read in and then appended. Column names were added and the new file exported.

```{r together}
one <- read.csv(file = '/rds/projects/g/grievej-german-dialect-profiling/extracted/1.csv')
two <- read.csv(file = '/rds/projects/g/grievej-german-dialect-profiling/extracted/2.csv')
three <- read.csv(file = '/rds/projects/g/grievej-german-dialect-profiling/extracted/3.csv')
four <- read.csv(file = '/rds/projects/g/grievej-german-dialect-profiling/extracted/4.csv')
five <- read.csv(file = '/rds/projects/g/grievej-german-dialect-profiling/extracted/5.csv')
six <- read.csv(file = '/rds/projects/g/grievej-german-dialect-profiling/extracted/6.csv')
seven <- read.csv(file = '/rds/projects/g/grievej-german-dialect-profiling/extracted/7.csv')
eight <- read.csv(file = '/rds/projects/g/grievej-german-dialect-profiling/extracted/8.csv')
nine <- read.csv(file = '/rds/projects/g/grievej-german-dialect-profiling/extracted/9.csv')
ten <- read.csv(file = '/rds/projects/g/grievej-german-dialect-profiling/extracted/10.csv')
eleven <- read.csv(file = '/rds/projects/g/grievej-german-dialect-profiling/extracted/11.csv')
twelve <- read.csv(file = '/rds/projects/g/grievej-german-dialect-profiling/extracted/12.csv')
thirteen <- read.csv(file = '/rds/projects/g/grievej-german-dialect-profiling/extracted/13.csv')
part1 <- rbind(one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen)
colnames(part1) <- c("message", "created_at", "location", "post_id")
write.csv(part1,"/rds/projects/g/grievej-german-dialect-profiling/part1.csv", fileEncoding = "UTF-8", row.names = FALSE)

A <- read.csv(file = '/rds/projects/g/grievej-german-dialect-profiling/extracted/A.csv')
B <- read.csv(file = '/rds/projects/g/grievej-german-dialect-profiling/extracted/B.csv')
C <- read.csv(file = '/rds/projects/g/grievej-german-dialect-profiling/extracted/C.csv')
D <- read.csv(file = '/rds/projects/g/grievej-german-dialect-profiling/extracted/D.csv')
E <- read.csv(file = '/rds/projects/g/grievej-german-dialect-profiling/extracted/E.csv')
FF <- read.csv(file = '/rds/projects/g/grievej-german-dialect-profiling/extracted/F.csv')
G <- read.csv(file = '/rds/projects/g/grievej-german-dialect-profiling/extracted/G.csv')
H <- read.csv(file = '/rds/projects/g/grievej-german-dialect-profiling/extracted/H.csv')
I <- read.csv(file = '/rds/projects/g/grievej-german-dialect-profiling/extracted/I.csv')
J <- read.csv(file = '/rds/projects/g/grievej-german-dialect-profiling/extracted/J.csv')
K <- read.csv(file = '/rds/projects/g/grievej-german-dialect-profiling/extracted/K.csv')
L <- read.csv(file = '/rds/projects/g/grievej-german-dialect-profiling/extracted/L.csv')
M <- read.csv(file = '/rds/projects/g/grievej-german-dialect-profiling/extracted/M.csv')
N <- read.csv(file = '/rds/projects/g/grievej-german-dialect-profiling/extracted/N.csv')
O <- read.csv(file = '/rds/projects/g/grievej-german-dialect-profiling/extracted/O.csv')
P <- read.csv(file = '/rds/projects/g/grievej-german-dialect-profiling/extracted/P.csv')

part2 <- rbind(A, B, C, D, E, FF, G, H, I, J, K, L, M, N, O, P)
colnames(part2) <- c("message", "created_at", "location", "post_id")
write.csv(part2,"/rds/projects/g/grievej-german-dialect-profiling/part2.csv", fileEncoding = "UTF-8", row.names = FALSE)

total <- rbind(part1, part2)
write.csv(total,"/rds/projects/g/grievej-german-dialect-profiling/total.csv", fileEncoding = "UTF-8", row.names = FALSE)
```

