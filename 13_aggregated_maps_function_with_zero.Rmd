---
title: "Aggregated Maps With Zeros"
author: "Dana Roemling"
date: '2023-07-26'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Map Aggregation Function

This Markdown has all the bits for the function to aggregate maps by just inputting text. The first two pieces just need to run as they are, they set up the function (2) and load all the necessary bits (1) so that the code will run.

There are two bits where code needs to be changed. One is the input of strings which needs to be adjusted, the other is the name of the aggregated map for exporting.

First, run the setup, so that R has all the things it needs.

```{r setup}
# libraries
library(dplyr)
library(spdep)
library(sf)
library(sp)
library(tidyverse)
library(gstat)
library(stringr) 
library(scales)
library(classInt)
library(viridis)
library(viridisLite)
library(rnaturalearth)
library(sfheaders)

# data
longlat <- read.csv(file = './data_maps/gsa_geo_filtered.csv')
longlat_only <- longlat %>% dplyr::select(lon, lat)
corpus <- read.csv(file = './data_ling/full_matrix_for_filtering.csv') 
token_at_location <- read.csv(file = './data_ling/tokens_at_location.csv')
colnames(token_at_location) <- c("City", "Tokencount") 
longlat_small <- read.csv(file = './data_maps/gsa_geo_filtered_nosmall22.csv')
longlat_small <- read.csv(file = './data_maps/gsa_geo_filtered_nosmall85.csv')

# set up mapping & kriging
cities <- data.frame(
  City = c("Köln", "München", "Wien", "Zürich", "Berlin", "Hamburg"),
  Long = c(6.9578, 11.5755, 16.3731, 8.5417, 13.3833, 10),
  Lat = c(50.9422, 48.1372, 48.2083, 47.3769, 52.5167, 53.55))
crs2 <- CRS("+init=epsg:4326")
cities_sf <- st_as_sf(cities, coords = c("Long", "Lat"), crs = crs2)

EU <- st_read(dsn="./data_maps/EU/Try/", layer="NUTS_RG_20M_2021_3035")
EU <- st_transform(EU, CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"))
gsa_outline <- ne_countries(country = c("Austria", "Germany", "Switzerland"), returnclass="sf", scale = "large")
gsa_plot <- gsa_outline %>% dplyr::select(geometry) # just the outlines of the three
gsa_spatial <- as_Spatial(gsa_plot) # new object as spatial instead of sf
sp_grid <- as.data.frame(spsample(gsa_spatial,
                                  n = 100000,
                                  type = "regular", # systematically aligned sampling
                                  offset = c(0.5,0.5))) # makes sure grid is the same every time
sp_grid_sf <- st_as_sf(sp_grid, coords=c("x1","x2"), crs = st_crs(4326))
sp_grid_small <- as.data.frame(spsample(gsa_spatial,
                                        n = 500,
                                        type = "regular", # systematically aligned sampling
                                        offset = c(0.5,0.5))) # makes sure grid is the same every time
sp_grid_sf_small <- st_as_sf(sp_grid_small, coords=c("x1","x2"), crs = st_crs(4326))

# establish data objects
morans_calc <- c()
kriged_data <- sf_to_df(sp_grid_sf, fill = TRUE)
kriged_data <- dplyr::select(kriged_data, "x", "y")
colnames(kriged_data) <- c("lon", "lat") 
```

## Functions

Run this to create the functions for the aggregation. First to calculate Moran's I. Then to do the kriging.

```{r moran}
morans_calc <- function(strings) {
  # setup space
  morans_calc <- c()
  
  for (qword in strings) {
    try(
      { 
      # extract word
      one_word <- corpus %>% filter(word == qword)
      colnames(one_word) <- c("Token", "City", "Frequency")
      new_join <- merge(longlat_small, one_word, by.x ="City", by.y = "City", all = TRUE)
      new_join <- new_join %>% dplyr::select("City", "lon", "lat", "Frequency")
      new_join[is.na(new_join)] <- 0
      merger <- merge(new_join, token_at_location, by.x ="City", by.y = "City")
      merger$relfreq <- (merger$Frequency/merger$Tokencount)
      merger$relfreq1000 <- (merger$relfreq*1000)
      colnames(merger) <- c("City", "lon", "lat", "Frequency", "TokenCount", "RelativeFrequency", "RelativeFrequencyThousand")
      merger_small <- merger %>% dplyr::select("City", "lon", "lat", "RelativeFrequency")
      merger_small <- merger_small[order(merger_small$lon,decreasing=TRUE),]
      print(paste0("Merger Done: ", qword))
      
      # calculate moran's I
      merger_single <- aggregate(merger_small$RelativeFrequency, by=list(lon=merger_small$lon, lat=merger_small$lat), FUN=mean)
      merger_single <- merger_single[order(merger_single$lon,decreasing=TRUE),]
      colnames(merger_single) <- c("lon", "lat", "RelativeFrequency")
      amount <- nrow(merger_single)
      percent_knn <- round((amount/100), 0)
      percent_knn <- if (percent_knn == 0) {
          percent_knn + 1
        } else {
          percent_knn
        }
      longlat_variable <- merger_single %>% dplyr::select(lon, lat)
      knn <- knn2nb(knearneigh(coordinates(longlat_variable), k = percent_knn, longlat = TRUE))
      knn <- include.self(knn)
      weighted_knn <- nb2listw(knn, style="W", zero.policy=TRUE)
      moran <- moran(merger_single$RelativeFrequency, weighted_knn, length(knn), Szero(weighted_knn))[1]
      output <- c(qword, moran)
      morans_calc = rbind(morans_calc, output)
      print(paste0("Morans Done: ", qword))

      }
    )
  }
  return (morans_calc) 
}  
```

This is the kriging function.

```{r kriging}
kriged_data <- function(strings) {
  # setup space
  kriged_data <- sf_to_df(sp_grid_sf, fill = TRUE)
  kriged_data <- dplyr::select(kriged_data, "x", "y")
  colnames(kriged_data) <- c("lon", "lat") 
  
  for (qword in strings) {
    try(
      { 
        # extract word
      one_word <- corpus %>% filter(word == qword)
      colnames(one_word) <- c("Token", "City", "Frequency")
      new_join <- merge(longlat_small, one_word, by.x ="City", by.y = "City", all = TRUE)
      new_join <- new_join %>% dplyr::select("City", "lon", "lat", "Frequency")
      new_join[is.na(new_join)] <- 0
      merger <- merge(new_join, token_at_location, by.x ="City", by.y = "City")
      merger$relfreq <- (merger$Frequency/merger$Tokencount)
      merger$relfreq1000 <- (merger$relfreq*1000)
      colnames(merger) <- c("City", "lon", "lat", "Frequency", "TokenCount", "RelativeFrequency", "RelativeFrequencyThousand")
      merger <- merger[order(merger$lon,decreasing=TRUE),]
      print(paste0("Merger Done: ", qword))
      
      # Variogram
      trial <- merger %>% dplyr::select("lon", "lat", "RelativeFrequencyThousand")
      data <- trial[3]
      coords <- trial[1:2]
      crs <- CRS("+init=epsg:4326") 
      spdf <- SpatialPointsDataFrame(coords      = coords,
                                     data        = data, 
                                     proj4string = crs)
      spdf = spdf[which(!duplicated(spdf@coords)), ]
      vg <- variogram(RelativeFrequencyThousand~1, data = spdf, width = 1, cutoff = 300)
      vg_fit <- fit.variogram(vg, vgm("Exp")) 
      print(paste0("Variogram Done: ", qword))
      
      # Kriging
      krig2 <- krige(RelativeFrequencyThousand~1, 
                     locations = spdf, 
                     newdata = sp_grid_sf_small, 
                     model = vg_fit)
      
      krig3 <- krige(var1.pred~1, 
                     locations = krig2, 
                     newdata = sp_grid_sf, 
                     model = vg_fit)
      print(paste0("Kriging Done: ", qword))
      
      # Scaling the kriged variables 
      krig3$scaledpred <- scale(krig3$var1.pred)
      krig3 <- plyr::rename(krig3, c("scaledpred" = qword))
      print(paste0("Scaling Done: ", qword))
      
      # add to kriged_data object
      krig3_notsf <- sf_to_df(krig3, fill = TRUE)
      krig3_notsf <- dplyr::select(krig3_notsf, qword, "x", "y")
      colnames(krig3_notsf) <- c(qword, "lon", "lat") 
      kriged_data <- merge(x = kriged_data, y = krig3_notsf, by.x = c("lon", "lat"), by.y = c("lon", "lat"), all.x=TRUE)
     
        }
    )
  }
  return (kriged_data)
}
```


## Input Data

Create an object with all the strings that should be mapped.

```{r string setup}
strings <- c("test")
strings <- c("hier", "sind", "worte")
strings <- c("Oder", "an", "besonderen", "Orten", "finde", "ich", "reizvoll")
```


## Run the Aggregation

Now we can run the aggregation. With this we can then create a map in the final step. 
Since Moran's I and kriging are separate functions, we need to run them both. 

```{r run aggregation}
morans_calc <- morans_calc(strings)
kriged_data <- kriged_data(strings)
```

## Calculate All the Bits

Here we need to do the actual aggregation after extracting all the values.

```{r calculate}
morans_calc <- as.data.frame(morans_calc)
colnames(morans_calc) <- c("word", "score") 
rownames(morans_calc) <- 1:nrow(morans_calc)

# get which words are in kriged_data and exclude long/lat
word_columns <- names(kriged_data)[sapply(kriged_data, is.numeric)]
word_columns <- setdiff(word_columns, c("lon", "lat"))

# multiply kriged_data with moran's values
for (word in word_columns) {
  if (word %in% morans_calc$word) {
    word_score <- as.numeric(morans_calc$score[morans_calc$word == word])
    print(paste0("Word: ", word))
    print(paste0("Score: ", word_score))
    print(paste0("Index: ", match(word, morans_calc$word)))
    kriged_data[, paste0(word, "_multiplied")] <- as.numeric(kriged_data[, word]) * word_score
  }
}

# mean over kriged values multiplied with moran's i
multiplied_columns <- paste0(word_columns, "_multiplied")
calculation <- kriged_data %>%
  dplyr::select(lon, lat, all_of(multiplied_columns))
calculation$mean_val <- rowMeans(calculation[, multiplied_columns], na.rm = TRUE)
calculation$median_val <- apply(calculation[, multiplied_columns], 1, median, na.rm = TRUE)
calculation$sd_val <- apply(calculation[, multiplied_columns], 1, sd, na.rm = TRUE)
calculation_sf <- st_as_sf(calculation, coords = c("lon", "lat"), crs = crs2)

# outside loop I create the final map
legend_max <- round(max(calculation$mean), digits = 2)
legend_min <- round(min(calculation$mean), digits = 2)
```

## Finally, Map

This will output a map to the directory given below.

```{r map}
# make that one map
tiff(paste0("/Users/dana/Documents/R/PHD/aggregated_output/cologne.tiff"), units="in", width=3.8, height=5, res=300)
print(
ggplot() +
  geom_sf(data = calculation_sf, aes(fill=mean_val), shape = 21, size = 0.75, stroke = 0, lwd = 0) +
  geom_sf(data = gsa_plot, aes(geometry = geometry), color="black", fill=NA, size = 0.5) +
  geom_sf_text(data = cities_sf, aes(label = City), size = 2.5, nudge_x = 0, nudge_y = -0.15, family = "Optima") +
  geom_sf(data = cities_sf, aes(geometry = geometry), shape = 4) +
  theme_minimal() +
  scale_fill_steps(low="#ffffff", high="#310d59", n.breaks = 20, labels = NULL) +
  theme(axis.title.x = element_blank(), 
        axis.title.y = element_blank(),
        axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        panel.grid.major = element_blank()) +
  theme(legend.position = c(0.90, 0.65), 
        legend.title = element_text(size = 6, family = "Optima"), 
        legend.text = element_text(size = 6, family = "Optima", hjust = 1),
        legend.title.align = 0,
        legend.key.size = unit(0.3, "cm"),
        legend.key.width = unit(0.4,"cm")) +
  annotate(geom="text", x = 17, y = 52.4, label=legend_max, size = 1.5, family = "Optima") +
  annotate(geom="text", x = 17, y = 51.3, label=legend_min, size = 1.5, family = "Optima") +
  #annotate(geom="text", x = 16.2, y = 49.8, label="danaroemling.com", size = 2.5, family = "Optima") +
  #annotate(geom="text", x = 16.2, y = 49.6, label="03/04/2023", size = 2.5, family = "Optima") +
  labs(fill = " ")
)
dev.off()
print(paste0("Tiff Done."))
```

